{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmnrl4s5QdSW"
      },
      "source": [
        "# **Convolutional Neural Network (CNN) Architecture**\n",
        "\n",
        "Model definition, build and configuration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-6KReLY1T9U"
      },
      "outputs": [],
      "source": [
        "# CNN configuration parameters\n",
        "class TCNNConfig(object):\n",
        "\n",
        "    embedding_dim = 128  # Word vector dimension\n",
        "    seq_length = max_length  # Sequence length (Taken from preprocessing)\n",
        "    num_classes = num_classes # Number of classes (Taken from preprocessing)\n",
        "    num_filters = 256  # Number of convolution kernels\n",
        "    kernel_size = 5  # Convolution kernel size\n",
        "    vocab_size = len(word_index) + 1 # Small vocabulary expression (Taken from tokenizer)\n",
        "\n",
        "    hidden_dim = 128  # Fully connected layer neurons\n",
        "\n",
        "    dropout_keep_prob = 0.5  # Dropout retentio ratio\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    batch_size = 64  # Training size per batch\n",
        "    num_epochs = 10\n",
        "\n",
        "    print_per_batch = 100\n",
        "    save_per_batch = 10\n",
        "\n",
        "# CNN model build\n",
        "class TextCNN(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(self.config.vocab_size, self.config.embedding_dim)\n",
        "        self.conv1 = tf.keras.layers.Conv1D(self.config.num_filters, self.config.kernel_size, activation='relu')\n",
        "        self.pool1 = tf.keras.layers.GlobalMaxPooling1D()\n",
        "        self.fc1 = tf.keras.layers.Dense(self.config.hidden_dim, activation='relu')\n",
        "        self.dropout = tf.keras.layers.Dropout(self.config.dropout_keep_prob)\n",
        "        self.fc2 = tf.keras.layers.Dense(self.config.num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embedding_inputs = self.embedding(inputs)\n",
        "        conv = self.conv1(embedding_inputs)\n",
        "        gmp = self.pool1(conv)\n",
        "        fc = self.fc1(gmp)\n",
        "        fc = self.dropout(fc)\n",
        "        logits = self.fc2(fc)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sNf7gfJVpZk",
        "outputId": "f2809351-a548-48d9-d74b-b64c3eefc598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "Epoch 1/10 Batch 0 Loss: 1.4144 Accuracy: 0.1719\n",
            "Epoch 1/10 Batch 100 Loss: 1.0256 Accuracy: 0.5702\n",
            "Epoch 1/10 Batch 200 Loss: 0.7079 Accuracy: 0.7219\n",
            "Epoch 1/10 Batch 300 Loss: 0.5849 Accuracy: 0.7772\n",
            "Epoch 1/10 Batch 400 Loss: 0.5171 Accuracy: 0.8061\n",
            "Epoch 1/10 Batch 500 Loss: 0.4760 Accuracy: 0.8241\n",
            "Epoch 1/10 Batch 600 Loss: 0.4463 Accuracy: 0.8363\n",
            "Epoch 1/10 Batch 700 Loss: 0.4244 Accuracy: 0.8455\n",
            "Epoch 1/10 Batch 800 Loss: 0.4098 Accuracy: 0.8515\n",
            "Epoch 1/10 Batch 900 Loss: 0.3941 Accuracy: 0.8579\n",
            "Epoch 1/10 Batch 1000 Loss: 0.3831 Accuracy: 0.8626\n",
            "Epoch 1/10 Batch 1100 Loss: 0.3731 Accuracy: 0.8666\n",
            "Epoch 1/10 Batch 1200 Loss: 0.3642 Accuracy: 0.8700\n",
            "Epoch 1/10 Batch 1300 Loss: 0.3584 Accuracy: 0.8721\n",
            "Epoch 1/10 Batch 1400 Loss: 0.3511 Accuracy: 0.8751\n",
            "Epoch 1/10 Validation Loss: 0.2636 Validation Accuracy: 0.9103\n",
            "Epoch 2/10 Batch 0 Loss: 0.2547 Accuracy: 0.9219\n",
            "Epoch 2/10 Batch 100 Loss: 0.1947 Accuracy: 0.9313\n",
            "Epoch 2/10 Batch 200 Loss: 0.1975 Accuracy: 0.9320\n",
            "Epoch 2/10 Batch 300 Loss: 0.1986 Accuracy: 0.9319\n",
            "Epoch 2/10 Batch 400 Loss: 0.1963 Accuracy: 0.9324\n",
            "Epoch 2/10 Batch 500 Loss: 0.1942 Accuracy: 0.9328\n",
            "Epoch 2/10 Batch 600 Loss: 0.1950 Accuracy: 0.9320\n",
            "Epoch 2/10 Batch 700 Loss: 0.1953 Accuracy: 0.9320\n",
            "Epoch 2/10 Batch 800 Loss: 0.1970 Accuracy: 0.9310\n",
            "Epoch 2/10 Batch 900 Loss: 0.1988 Accuracy: 0.9303\n",
            "Epoch 2/10 Batch 1000 Loss: 0.2013 Accuracy: 0.9291\n",
            "Epoch 2/10 Batch 1100 Loss: 0.2023 Accuracy: 0.9292\n",
            "Epoch 2/10 Batch 1200 Loss: 0.2038 Accuracy: 0.9287\n",
            "Epoch 2/10 Batch 1300 Loss: 0.2047 Accuracy: 0.9285\n",
            "Epoch 2/10 Batch 1400 Loss: 0.2035 Accuracy: 0.9288\n",
            "Epoch 2/10 Validation Loss: 0.2559 Validation Accuracy: 0.9162\n",
            "Epoch 3/10 Batch 0 Loss: 0.0751 Accuracy: 0.9844\n",
            "Epoch 3/10 Batch 100 Loss: 0.1175 Accuracy: 0.9612\n",
            "Epoch 3/10 Batch 200 Loss: 0.1197 Accuracy: 0.9605\n",
            "Epoch 3/10 Batch 300 Loss: 0.1189 Accuracy: 0.9609\n",
            "Epoch 3/10 Batch 400 Loss: 0.1176 Accuracy: 0.9606\n",
            "Epoch 3/10 Batch 500 Loss: 0.1193 Accuracy: 0.9599\n",
            "Epoch 3/10 Batch 600 Loss: 0.1202 Accuracy: 0.9597\n",
            "Epoch 3/10 Batch 700 Loss: 0.1211 Accuracy: 0.9593\n",
            "Epoch 3/10 Batch 800 Loss: 0.1230 Accuracy: 0.9583\n",
            "Epoch 3/10 Batch 900 Loss: 0.1258 Accuracy: 0.9570\n",
            "Epoch 3/10 Batch 1000 Loss: 0.1270 Accuracy: 0.9566\n",
            "Epoch 3/10 Batch 1100 Loss: 0.1276 Accuracy: 0.9562\n",
            "Epoch 3/10 Batch 1200 Loss: 0.1291 Accuracy: 0.9553\n",
            "Epoch 3/10 Batch 1300 Loss: 0.1303 Accuracy: 0.9548\n",
            "Epoch 3/10 Batch 1400 Loss: 0.1315 Accuracy: 0.9544\n",
            "Epoch 3/10 Validation Loss: 0.2906 Validation Accuracy: 0.9115\n",
            "Epoch 4/10 Batch 0 Loss: 0.0744 Accuracy: 0.9844\n",
            "Epoch 4/10 Batch 100 Loss: 0.0645 Accuracy: 0.9802\n",
            "Epoch 4/10 Batch 200 Loss: 0.0604 Accuracy: 0.9803\n",
            "Epoch 4/10 Batch 300 Loss: 0.0585 Accuracy: 0.9807\n",
            "Epoch 4/10 Batch 400 Loss: 0.0569 Accuracy: 0.9808\n",
            "Epoch 4/10 Batch 500 Loss: 0.0575 Accuracy: 0.9806\n",
            "Epoch 4/10 Batch 600 Loss: 0.0583 Accuracy: 0.9802\n",
            "Epoch 4/10 Batch 700 Loss: 0.0598 Accuracy: 0.9799\n",
            "Epoch 4/10 Batch 800 Loss: 0.0609 Accuracy: 0.9795\n",
            "Epoch 4/10 Batch 900 Loss: 0.0621 Accuracy: 0.9790\n",
            "Epoch 4/10 Batch 1000 Loss: 0.0629 Accuracy: 0.9788\n",
            "Epoch 4/10 Batch 1100 Loss: 0.0652 Accuracy: 0.9780\n",
            "Epoch 4/10 Batch 1200 Loss: 0.0670 Accuracy: 0.9772\n",
            "Epoch 4/10 Batch 1300 Loss: 0.0681 Accuracy: 0.9768\n",
            "Epoch 4/10 Batch 1400 Loss: 0.0690 Accuracy: 0.9763\n",
            "Epoch 4/10 Validation Loss: 0.3541 Validation Accuracy: 0.9085\n",
            "Epoch 5/10 Batch 0 Loss: 0.0594 Accuracy: 0.9844\n",
            "Epoch 5/10 Batch 100 Loss: 0.0358 Accuracy: 0.9878\n",
            "Epoch 5/10 Batch 200 Loss: 0.0321 Accuracy: 0.9894\n",
            "Epoch 5/10 Batch 300 Loss: 0.0312 Accuracy: 0.9899\n",
            "Epoch 5/10 Batch 400 Loss: 0.0313 Accuracy: 0.9898\n",
            "Epoch 5/10 Batch 500 Loss: 0.0321 Accuracy: 0.9898\n",
            "Epoch 5/10 Batch 600 Loss: 0.0343 Accuracy: 0.9889\n",
            "Epoch 5/10 Batch 700 Loss: 0.0369 Accuracy: 0.9884\n",
            "Epoch 5/10 Batch 800 Loss: 0.0381 Accuracy: 0.9880\n",
            "Epoch 5/10 Batch 900 Loss: 0.0378 Accuracy: 0.9881\n",
            "Epoch 5/10 Batch 1000 Loss: 0.0397 Accuracy: 0.9873\n",
            "Epoch 5/10 Batch 1100 Loss: 0.0400 Accuracy: 0.9870\n",
            "Epoch 5/10 Batch 1200 Loss: 0.0404 Accuracy: 0.9871\n",
            "Epoch 5/10 Batch 1300 Loss: 0.0407 Accuracy: 0.9869\n",
            "Epoch 5/10 Batch 1400 Loss: 0.0406 Accuracy: 0.9867\n",
            "Epoch 5/10 Validation Loss: 0.4332 Validation Accuracy: 0.9022\n",
            "Epoch 6/10 Batch 0 Loss: 0.0091 Accuracy: 1.0000\n",
            "Epoch 6/10 Batch 100 Loss: 0.0180 Accuracy: 0.9958\n",
            "Epoch 6/10 Batch 200 Loss: 0.0202 Accuracy: 0.9949\n",
            "Epoch 6/10 Batch 300 Loss: 0.0221 Accuracy: 0.9942\n",
            "Epoch 6/10 Batch 400 Loss: 0.0234 Accuracy: 0.9936\n",
            "Epoch 6/10 Batch 500 Loss: 0.0240 Accuracy: 0.9931\n",
            "Epoch 6/10 Batch 600 Loss: 0.0246 Accuracy: 0.9927\n",
            "Epoch 6/10 Batch 700 Loss: 0.0252 Accuracy: 0.9926\n",
            "Epoch 6/10 Batch 800 Loss: 0.0272 Accuracy: 0.9919\n",
            "Epoch 6/10 Batch 900 Loss: 0.0282 Accuracy: 0.9917\n",
            "Epoch 6/10 Batch 1000 Loss: 0.0288 Accuracy: 0.9915\n",
            "Epoch 6/10 Batch 1100 Loss: 0.0305 Accuracy: 0.9909\n",
            "Epoch 6/10 Batch 1200 Loss: 0.0310 Accuracy: 0.9906\n",
            "Epoch 6/10 Batch 1300 Loss: 0.0320 Accuracy: 0.9904\n",
            "Epoch 6/10 Batch 1400 Loss: 0.0328 Accuracy: 0.9900\n",
            "Epoch 6/10 Validation Loss: 0.4692 Validation Accuracy: 0.9060\n",
            "Epoch 7/10 Batch 0 Loss: 0.0147 Accuracy: 1.0000\n",
            "Epoch 7/10 Batch 100 Loss: 0.0193 Accuracy: 0.9943\n",
            "Epoch 7/10 Batch 200 Loss: 0.0188 Accuracy: 0.9949\n",
            "Epoch 7/10 Batch 300 Loss: 0.0194 Accuracy: 0.9948\n",
            "Epoch 7/10 Batch 400 Loss: 0.0190 Accuracy: 0.9953\n",
            "Epoch 7/10 Batch 500 Loss: 0.0198 Accuracy: 0.9949\n",
            "Epoch 7/10 Batch 600 Loss: 0.0209 Accuracy: 0.9945\n",
            "Epoch 7/10 Batch 700 Loss: 0.0223 Accuracy: 0.9939\n",
            "Epoch 7/10 Batch 800 Loss: 0.0226 Accuracy: 0.9938\n",
            "Epoch 7/10 Batch 900 Loss: 0.0224 Accuracy: 0.9939\n",
            "Epoch 7/10 Batch 1000 Loss: 0.0228 Accuracy: 0.9938\n",
            "Epoch 7/10 Batch 1100 Loss: 0.0231 Accuracy: 0.9935\n",
            "Epoch 7/10 Batch 1200 Loss: 0.0237 Accuracy: 0.9932\n",
            "Epoch 7/10 Batch 1300 Loss: 0.0244 Accuracy: 0.9929\n",
            "Epoch 7/10 Batch 1400 Loss: 0.0253 Accuracy: 0.9925\n",
            "Epoch 7/10 Validation Loss: 0.5301 Validation Accuracy: 0.9040\n",
            "Epoch 8/10 Batch 0 Loss: 0.0029 Accuracy: 1.0000\n",
            "Epoch 8/10 Batch 100 Loss: 0.0272 Accuracy: 0.9912\n",
            "Epoch 8/10 Batch 200 Loss: 0.0192 Accuracy: 0.9940\n",
            "Epoch 8/10 Batch 300 Loss: 0.0193 Accuracy: 0.9937\n",
            "Epoch 8/10 Batch 400 Loss: 0.0194 Accuracy: 0.9939\n",
            "Epoch 8/10 Batch 500 Loss: 0.0212 Accuracy: 0.9935\n",
            "Epoch 8/10 Batch 600 Loss: 0.0214 Accuracy: 0.9935\n",
            "Epoch 8/10 Batch 700 Loss: 0.0213 Accuracy: 0.9933\n",
            "Epoch 8/10 Batch 800 Loss: 0.0212 Accuracy: 0.9934\n",
            "Epoch 8/10 Batch 900 Loss: 0.0216 Accuracy: 0.9932\n",
            "Epoch 8/10 Batch 1000 Loss: 0.0232 Accuracy: 0.9926\n",
            "Epoch 8/10 Batch 1100 Loss: 0.0241 Accuracy: 0.9924\n",
            "Epoch 8/10 Batch 1200 Loss: 0.0246 Accuracy: 0.9921\n",
            "Epoch 8/10 Batch 1300 Loss: 0.0257 Accuracy: 0.9919\n",
            "Epoch 8/10 Batch 1400 Loss: 0.0259 Accuracy: 0.9919\n",
            "Epoch 8/10 Validation Loss: 0.5413 Validation Accuracy: 0.9059\n",
            "Epoch 9/10 Batch 0 Loss: 0.0035 Accuracy: 1.0000\n",
            "Epoch 9/10 Batch 100 Loss: 0.0144 Accuracy: 0.9958\n",
            "Epoch 9/10 Batch 200 Loss: 0.0152 Accuracy: 0.9954\n",
            "Epoch 9/10 Batch 300 Loss: 0.0146 Accuracy: 0.9955\n",
            "Epoch 9/10 Batch 400 Loss: 0.0145 Accuracy: 0.9957\n",
            "Epoch 9/10 Batch 500 Loss: 0.0137 Accuracy: 0.9960\n",
            "Epoch 9/10 Batch 600 Loss: 0.0141 Accuracy: 0.9958\n",
            "Epoch 9/10 Batch 700 Loss: 0.0139 Accuracy: 0.9958\n",
            "Epoch 9/10 Batch 800 Loss: 0.0146 Accuracy: 0.9956\n",
            "Epoch 9/10 Batch 900 Loss: 0.0151 Accuracy: 0.9952\n",
            "Epoch 9/10 Batch 1000 Loss: 0.0160 Accuracy: 0.9949\n",
            "Epoch 9/10 Batch 1100 Loss: 0.0163 Accuracy: 0.9948\n",
            "Epoch 9/10 Batch 1200 Loss: 0.0170 Accuracy: 0.9945\n",
            "Epoch 9/10 Batch 1300 Loss: 0.0174 Accuracy: 0.9944\n",
            "Epoch 9/10 Batch 1400 Loss: 0.0176 Accuracy: 0.9943\n",
            "Epoch 9/10 Validation Loss: 0.5682 Validation Accuracy: 0.9040\n",
            "Epoch 10/10 Batch 0 Loss: 0.0047 Accuracy: 1.0000\n",
            "Epoch 10/10 Batch 100 Loss: 0.0153 Accuracy: 0.9947\n",
            "Epoch 10/10 Batch 200 Loss: 0.0156 Accuracy: 0.9949\n",
            "Epoch 10/10 Batch 300 Loss: 0.0146 Accuracy: 0.9953\n",
            "Epoch 10/10 Batch 400 Loss: 0.0151 Accuracy: 0.9951\n",
            "Epoch 10/10 Batch 500 Loss: 0.0158 Accuracy: 0.9947\n",
            "Epoch 10/10 Batch 600 Loss: 0.0160 Accuracy: 0.9947\n",
            "Epoch 10/10 Batch 700 Loss: 0.0154 Accuracy: 0.9949\n",
            "Epoch 10/10 Batch 800 Loss: 0.0155 Accuracy: 0.9950\n",
            "Epoch 10/10 Batch 900 Loss: 0.0156 Accuracy: 0.9951\n",
            "Epoch 10/10 Batch 1000 Loss: 0.0159 Accuracy: 0.9951\n",
            "Epoch 10/10 Batch 1100 Loss: 0.0163 Accuracy: 0.9949\n",
            "Epoch 10/10 Batch 1200 Loss: 0.0174 Accuracy: 0.9946\n",
            "Epoch 10/10 Batch 1300 Loss: 0.0178 Accuracy: 0.9945\n",
            "Epoch 10/10 Batch 1400 Loss: 0.0181 Accuracy: 0.9943\n",
            "Epoch 10/10 Validation Loss: 0.6033 Validation Accuracy: 0.9058\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "config = TCNNConfig()\n",
        "model = TextCNN(config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(config.learning_rate)\n",
        "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "def train_step(inputs, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs)\n",
        "        loss = loss_func(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    accuracy = np.mean(np.argmax(labels, axis=1) == np.argmax(predictions, axis=1))\n",
        "    return loss, accuracy\n",
        "\n",
        "def evaluate_model(inputs, labels):\n",
        "    predictions = model(inputs)\n",
        "    loss = loss_func(labels, predictions)\n",
        "    accuracy = np.mean(np.argmax(labels, axis=1) == np.argmax(predictions, axis=1))\n",
        "    return loss, accuracy\n",
        "\n",
        "epochs = config.num_epochs\n",
        "batch_size = config.batch_size\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_padded, y_train_one_hot)).shuffle(len(X_train_padded)).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_padded, y_val_one_hot)).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_padded, y_test_one_hot)).batch(batch_size)\n",
        "\n",
        "# Initialize lists to store losses and accuracies\n",
        "train_losses_cnn = []\n",
        "val_losses_cnn = []\n",
        "train_accuracies_cnn = []\n",
        "val_accuracies_cnn = []\n",
        "\n",
        "print(\"Training the model...\")\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_accuracy = tf.keras.metrics.Mean()\n",
        "    for batch, (inputs, labels) in enumerate(train_dataset):\n",
        "        loss, accuracy = train_step(inputs, labels)\n",
        "        epoch_loss_avg.update_state(loss)\n",
        "        epoch_accuracy.update_state(accuracy)\n",
        "        if batch % config.print_per_batch == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} Batch {batch} Loss: {epoch_loss_avg.result():.4f} Accuracy: {epoch_accuracy.result():.4f}\")\n",
        "\n",
        "    # Append epoch losses and accuracies to the lists\n",
        "    train_losses_cnn.append(epoch_loss_avg.result().numpy())\n",
        "    train_accuracies_cnn.append(epoch_accuracy.result().numpy())\n",
        "\n",
        "    val_loss_avg = tf.keras.metrics.Mean()\n",
        "    val_accuracy = tf.keras.metrics.Mean()\n",
        "    for inputs, labels in val_dataset:\n",
        "        loss, accuracy = evaluate_model(inputs, labels)\n",
        "        val_loss_avg.update_state(loss)\n",
        "        val_accuracy.update_state(accuracy)\n",
        "\n",
        "    # Append epoch losses and accuracies to the lists\n",
        "    val_losses_cnn.append(val_loss_avg.result().numpy())\n",
        "    val_accuracies_cnn.append(val_accuracy.result().numpy())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} Validation Loss: {val_loss_avg.result():.4f} Validation Accuracy: {val_accuracy.result():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB0Tok8PWMca",
        "outputId": "8632e62d-a5c7-4719-cf2a-c55e62c29c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"text_cnn_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     multiple                  8872320   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           multiple                  164096    \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Gl  multiple                  0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             multiple                  32896     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             multiple                  516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9069828 (34.60 MB)\n",
            "Trainable params: 9069828 (34.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3GNTJx1wmIn",
        "outputId": "338cf427-6412-4cc7-a2ac-a51416944943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on the test set...\n",
            "Test Loss: 0.6398 Test Accuracy: 0.9026\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluating on the test set...\")\n",
        "test_loss_avg = tf.keras.metrics.Mean()\n",
        "test_accuracy = tf.keras.metrics.Mean()\n",
        "for inputs, labels in test_dataset:\n",
        "    loss, accuracy = evaluate_model(inputs, labels)\n",
        "    test_loss_avg.update_state(loss)\n",
        "    test_accuracy.update_state(accuracy)\n",
        "print(f\"Test Loss: {test_loss_avg.result():.4f} Test Accuracy: {test_accuracy.result():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}