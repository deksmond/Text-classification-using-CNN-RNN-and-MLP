# -*- coding: utf-8 -*-
"""cnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CQSoIcD-nBwXyEkX8iTto7ED4EA_qFwX

# **Convolutional Neural Network (CNN)**
"""

# CNN configuration parameters
class TCNNConfig(object):

    embedding_dim = 128  # Word vector dimension
    seq_length = max_length  # Sequence length (Taken from preprocessing)
    num_classes = num_classes # Number of classes (Taken from preprocessing)
    num_filters = 256  # Number of convolution kernels
    kernel_size = 5  # Convolution kernel size
    vocab_size = len(word_index) + 1 # Small vocabulary expression (Taken from tokenizer)

    hidden_dim = 128  # Fully connected layer neurons

    dropout_keep_prob = 0.5  # Dropout retentio ratio
    learning_rate = 1e-3

    batch_size = 64  # Training size per batch
    num_epochs = 10

    print_per_batch = 100
    save_per_batch = 10

# CNN model build
class TextCNN(tf.keras.Model):

    def __init__(self, config):
        super(TextCNN, self).__init__()
        self.config = config

        self.embedding = tf.keras.layers.Embedding(self.config.vocab_size, self.config.embedding_dim)
        self.conv1 = tf.keras.layers.Conv1D(self.config.num_filters, self.config.kernel_size, activation='relu')
        self.pool1 = tf.keras.layers.GlobalMaxPooling1D()
        self.fc1 = tf.keras.layers.Dense(self.config.hidden_dim, activation='relu')
        self.dropout = tf.keras.layers.Dropout(self.config.dropout_keep_prob)
        self.fc2 = tf.keras.layers.Dense(self.config.num_classes, activation='softmax')

    def call(self, inputs):
        embedding_inputs = self.embedding(inputs)
        conv = self.conv1(embedding_inputs)
        gmp = self.pool1(conv)
        fc = self.fc1(gmp)
        fc = self.dropout(fc)
        logits = self.fc2(fc)
        return logits

"""**Convolutional Neural Network (CNN) training and evaluation**

The Model Training sets up the training process for CNN. It initializes the model, optimizer, and loss function. It defines functions for a single training step (train_step) and evaluation (evaluate_model). It prepares the training, validation, and test datasets in batches. Then, it runs the main training loop, iterating through epochs and batches, performing training steps, evaluating on the validation set after each epoch, tracking loss and accuracy, and printing progress. Finally, it prints a summary of the trained model's architecture.


"""

# Model Training
config = TCNNConfig()
model = TextCNN(config)

optimizer = tf.keras.optimizers.Adam(config.learning_rate)
loss_func = tf.keras.losses.CategoricalCrossentropy()

def train_step(inputs, labels):
    with tf.GradientTape() as tape:
        predictions = model(inputs)
        loss = loss_func(labels, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    accuracy = np.mean(np.argmax(labels, axis=1) == np.argmax(predictions, axis=1))
    return loss, accuracy

def evaluate_model(inputs, labels):
    predictions = model(inputs)
    loss = loss_func(labels, predictions)
    accuracy = np.mean(np.argmax(labels, axis=1) == np.argmax(predictions, axis=1))
    return loss, accuracy

epochs = config.num_epochs
batch_size = config.batch_size
train_dataset = tf.data.Dataset.from_tensor_slices((X_train_padded, y_train_one_hot)).shuffle(len(X_train_padded)).batch(batch_size)
val_dataset = tf.data.Dataset.from_tensor_slices((X_val_padded, y_val_one_hot)).batch(batch_size)
test_dataset = tf.data.Dataset.from_tensor_slices((X_test_padded, y_test_one_hot)).batch(batch_size)

# Initialize lists to store losses and accuracies
train_losses_cnn = []
val_losses_cnn = []
train_accuracies_cnn = []
val_accuracies_cnn = []

print("Training the model...")
for epoch in range(epochs):
    epoch_loss_avg = tf.keras.metrics.Mean()
    epoch_accuracy = tf.keras.metrics.Mean()
    for batch, (inputs, labels) in enumerate(train_dataset):
        loss, accuracy = train_step(inputs, labels)
        epoch_loss_avg.update_state(loss)
        epoch_accuracy.update_state(accuracy)
        if batch % config.print_per_batch == 0:
            print(f"Epoch {epoch+1}/{epochs} Batch {batch} Loss: {epoch_loss_avg.result():.4f} Accuracy: {epoch_accuracy.result():.4f}")

    # Append epoch losses and accuracies to the lists
    train_losses_cnn.append(epoch_loss_avg.result().numpy())
    train_accuracies_cnn.append(epoch_accuracy.result().numpy())

    val_loss_avg = tf.keras.metrics.Mean()
    val_accuracy = tf.keras.metrics.Mean()
    for inputs, labels in val_dataset:
        loss, accuracy = evaluate_model(inputs, labels)
        val_loss_avg.update_state(loss)
        val_accuracy.update_state(accuracy)

    # Append epoch losses and accuracies to the lists
    val_losses_cnn.append(val_loss_avg.result().numpy())
    val_accuracies_cnn.append(val_accuracy.result().numpy())

    print(f"Epoch {epoch+1}/{epochs} Validation Loss: {val_loss_avg.result():.4f} Validation Accuracy: {val_accuracy.result():.4f}")

model.summary()

print("\nEvaluating on the test set...")
test_loss_avg = tf.keras.metrics.Mean()
test_accuracy = tf.keras.metrics.Mean()
for inputs, labels in test_dataset:
    loss, accuracy = evaluate_model(inputs, labels)
    test_loss_avg.update_state(loss)
    test_accuracy.update_state(accuracy)
print(f"Test Loss: {test_loss_avg.result():.4f} Test Accuracy: {test_accuracy.result():.4f}")

"""**Model evaluation**

Trainin and validation loss
"""

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(train_losses_cnn, label='Training Loss')
plt.plot(val_losses_cnn, label='Validation Loss')
plt.title('CNN Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

"""Training and validation accuracy"""

plt.subplot(1, 2, 2)
plt.plot(train_accuracies_cnn, label='Training Accuracy')
plt.plot(val_accuracies_cnn, label='Validation Accuracy')
plt.title('CNN Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""Confusion matrix"""

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_pred_cnn = model.predict(X_test_padded)
y_pred_cnn_classes = np.argmax(y_pred_cnn, axis=1)
cm_cnn = confusion_matrix(np.argmax(y_test_one_hot, axis=1), y_pred_cnn_classes)
disp_cnn = ConfusionMatrixDisplay(confusion_matrix=cm_cnn, display_labels=label_encoder.classes_)
disp_cnn.plot(cmap=plt.cm.Blues)
plt.title('CNN Confusion Matrix')
plt.show()